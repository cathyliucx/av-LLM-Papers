# av-LLM-Papers-and-Projects 
Audio-visual large language model (av-LLM)  related papers &amp; projects, also extended to multi-modualities containing audio & visual info

## Papers 
### Year 2024
SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering https://arxiv.org/html/2411.04933v2
Enhancing Multimodal LLM for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization https://arxiv.org/html/2410.06682v1
video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models https://arxiv.org/abs/2406.15704
NExT-GPT: Any-to-Any Multimodal LLM https://arxiv.org/abs/2309.05519
Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration https://arxiv.org/abs/2306.09093
X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages https://arxiv.org/abs/2305.04160
Audio-visual training for improved grounding in video-text LLMs https://arxiv.org/abs/2407.15046
Audio-Visual LLM for Video Understanding https://arxiv.org/abs/2312.06720
Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding https://arxiv.org/abs/2403.16276
Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time https://arxiv.org/abs/2403.16276
### BF Year 2024
Spoken Moments: Learning Joint Audio-Visual Representations from Video Descriptions https://arxiv.org/abs/2105.04489
Language Is Not All You Need: Aligning Perception with Language Models  https://arxiv.org/abs/2302.14045
ImageBind: One Embedding Space To Bind Them All https://arxiv.org/abs/2305.05665
Video-LLaMAï¼šAn Instruction-tuned Audio-Visual Language Model for Video Understanding  https://arxiv.org/abs/2306.02858

## Projects
### Year 2024
